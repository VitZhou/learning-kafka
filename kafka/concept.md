# 概念
### Topics and Logs(主题和日志)
topic是发布记录的类别或者feed名称.kafka的topic是多用户的,也就是说topic可以有零个,一个或多个消费者订阅写入的数据.
对于每个topic,kafka集群都维护一个分区日志,如下图所示:
![](img/log_anatomy.png)
每个分区是一个有序的，不可变的记录序列，不断地附加到结构化提交日志。每个分区中的记录都被分配一个顺序的id号，作为唯一标识分区内每个记录的偏移量。
Kafka集群保留所有已发布的记录，无论它们是否已被消费----kafka可配置保留期。例如，如果保留期设置为两天，那么在发布记录后的两天内，记录都是可以被消费的，之后将被丢弃以释放空间。kafka不管数据量的大小都可以保证性能,所以长时间存储数据不是问题.

![](img/log_consumer.png)

事实上，在每个消费者基础上保留的唯一元数据是消费者在日志中的偏移量或位置. 这个偏移由消费者控制：通常消费者在读取记录时线性地提前其偏移，但是事实上，由于位置由消费者控制，所以它可以以它喜欢的任何顺序消费记录。 例如，消费者可以重置到较旧的偏移以重新处理来自过去的数据或者跳到最近的记录并从当前位置开始消费。

这种特征的组合意味着kafka消费者非常廉价 - 他们可以来去自如并且对集群或其他消费者没有太大的影响. 例如，您可以使用我们的命令行工具“跟踪”任何topic的内容,而无需更改任何现有用户使用的内容.

日志中的分区有几个目的. 首先,它们允许日志扩展到适合单个服务器的大小. 每个单独的分区必须适合托管它的服务器,但topic可能有许多分区,因此它可以处理任意数量级的数据.第二,它们是并行性单位 - 更多目的是在这一点。

### Distribution(分配)
日志的分区分布在Kafka集群中的服务器上,每个服务器处理数据并请求共享分区, 每个分区都跨越可配置数量的服务器进行复制，以实现容错。
每个分区都有一个服务器，充当“leader”,零个或多个服务器充当“followers”. leader处理分区的所有读取和写入请求，而follower被动地复制leader.如果leader挂了,其中一个follower将自动成为新的leader.每个服务器作为一些分区的leader,同时可以作为其他分区的follower,因此在集群内负载均衡良好.

### Producers(生产者)
生产者将数据发布择的topic.生产者负责选择哪个记录分配给topic内的哪个分区.这可以通过轮询方式简单地平衡负载,或者可以根据某些语义分区功能（例如基于记录中的某些关键字）来完成.

### Consumers(消费者)
消费者用consumer group name标注自己,并将push到topic的每条记录传递到订阅了consumer group的一个消费者实例.消费者实例可以在单独的进程或单独的机器上.

如果所有的消费者实例具有相同的consumer group,则记录将在消费者实例上有效地负载均衡.

如果所有的消费者实例都有不同的consumer group,那么每个记录将被广播给所有的消费者进程.

![](img/consumer-groups.png)

Kafka集群托管两个服务器四个分区（P0-P3）与两个consumer group.消费者组A有两个消费者实例,B组有四个。

然而,更常见的是,topic具有少量的consumer group,每个"logical subscriber"(逻辑订阅者)一个,为了扩展性和容错能力,每个consumer group由许多消费者实例组成.这是简单发布-订阅语义,订阅者是一个消费者集群而不是单个进程.

在Kafka中实现消费的方式是通过将日志中的分区划分到消费者实例上,以便每个实例都是任何时间点的“fair shard"分区的唯一消费者.维护组中成员资格的过程由Kafka协议动态处理.如果新的实例加入组,他们将从组中的其他成员接管一些分区; 如果一个实例消失,其分区将被分发到剩余的实例.

Kafka只提供一个分区内的记录的整体顺序,而不是一个主题的不同分区之间的顺序.每个分区排序结合按key分配数据的能力足以满足大多数应用程序的需求. 但是,如果您需要对记录进行总排序,可以使用只有一个分区的主题来实现,但这将意味着每个用户组只有一个消费者进程.

### 保障
高水准的kafka可以提供以下保障:
- 生产者发送到特定topic分区的消息将按照发送的顺序进行追加.也就是说,如果记录M1由与记录M2相同的生产者发送,并且首先发送M1,则M1将具有比M2更低的偏移并且在log.documentation中较早出现.
- 消费者实例按照它们(指的是记录)存储在日志中的顺序查看记录.
- 对于具有复制因子N的主题,我们将容忍最多N-1个服务器故障,而不会丢失提交到日志的任何记录.

有关这些保证的更多详细信息，请参见文档的设计部分。

### kafka作为消息传递系统
kafka的stream概念与传统的企业邮件系统相比如何？
消息传递系统传统上有两种模式:队列和发布-订阅.在队列中,一群消费者可以从系统中读取记录,每条记录都转到其中一个;在发布-订阅中,记录将广播给所有消费者。 这两个模型中的每一个都有优势和弱点.队列优点是它允许您在多个消费者实例上分配数据处理,从而可以扩展数据的处理能力, 可惜的,队列不是multi-subscriber(多订阅者)的 - 一旦一个进程读取数据,数据就会消失.发布-订阅允许将数据广播到多个进程,但无法缩放处理,因为每个消息都发送给每个用户.

kafka的consumer group概括了这两个概念.与队列一样,consumer group允许您通过一系列进程（consumer group的成员）来划分处理.与发布订阅一样,Kafka允许您将消息广播到多个consumer group.

kafka的模型的优势是每个topic都有以下两个属性:
- 可以拓展处理
- 多订阅的- 无需选择这个或者那个订阅者

Kafka比传统的邮件系统有更强大的订阅保证.

传统队列在服务器上保存顺序的记录,如果多个消费者从队列中消费,则服务器按照存储顺序输出记录.然而,虽然服务器按顺序输出记录,但是记录被异步传递给消费者,所以它们可能会在不同的按顺序到达消费者处.这意味着在并行消费的情况下,记录的顺序会丢失.消息传递系统通常通过使“exclusive consumer(唯一消费者)”的概念只能让一个进程从队列中消费,但这当然意味着处理中没有并行性.

Kafka做得更好.通过在主题中有一个并行概念(分区),Kafka能够在消费者流程池中提供排序保证和负载均衡.这是通过将topic中的分区分配给consumer group中的消费者实例来实现的,以便每个分区由group中的一个消费者实例消费.通过这样做,我们确保消费者实例是该分区的唯一读者,并按顺序消费数据.由于有许多分区,这仍然平衡了许多消费者实例的负载.但请注意,consumer group中的消费者实例不能超过分区数量.

### kafka作为存储系统
允许发布消息消费消息的任何消息队列有效地充当传递中消息的存储系统.在这一点kafka做得更好.

写入Kafka的数据写入磁盘并复制以进行容错.Kafka允许生产者等待确认,以便在完全复制之前写入不被认为是完整的,并且即使服务器写入失败,也保证持久化.

磁盘结构Kafka使用比例良好 ---- 无论您在服务器上是否有50 KB或50 TB的持久化数据,Kafka都会执行相同的操作。

作为存储并允许客户端控制其读取位置的结果,您可以将Kafka视为专用于高性能,低延迟的提交日志存储,复制和传播的专用分布式文件系统.

### Kafka Stream处理
仅读取,写入和存储数据流是不够的,目的是实现stream的实时处理.

在kafka中,stream处理器是从输入topic接收数据流的任何东西.对此输入执行一些处理,并生成持续的数据流以输出topic.例如,零售应用程序可能会收到销售和出货的输入流,并输出根据该数据计算的重新排序和价格调整.

可以直接使用生产者和消费者API进行简单处理,然而对于更复杂的转换,Kafka提供了一个完全集成的Streams API.它允许构建应用程序进行复杂处理,以计算流中的聚合或将流连接在一起.

这种方案有助于处理这些类型的应用所面临的困难:处理无序数据,输入代码更改后重新处理,执行有状态计算等.

Stream API基于Kafka提供的核心原语构建：它使用生产者和消费者API进行输入,使用Kafka进行有状态存储,并在流处理器实例之间使用相同的group机制来实现容错.

### Putting the Pieces Together(将组件整合在一起)
消息传递,存储和流处理的这种组合似乎是不寻常的,但是它们是kafka流媒体平台至关重要的角色.

像HDFS这样的分布式文件系统允许存储用于批处理的静态文件.这样一个有效的系统允许存储和处理来自过去的历史数据.

传统的企业邮件系统允许处理将在您订阅之后到达的未来邮件.以这种方式构建的应用程序在未来数据到达时处理.

Kafka组合了这两种功能,这组合对于Kafka作为流应用程序和流数据管道平台来说至关重要.

通过组合存储和低延迟订阅,流式应用程序可以以相同的方式处理过去和未来的数据.这是一个单一的应用程序可以处理历史记录数据.它可以在将来的数据到达时继续处理,而不是在最后一个记录到达时结束.这是一个广泛的流处理概念,其中包含批处理以及消息驱动应用.

类似的,对于流数据流水线(streaming data pipelines),订阅到实时事件的组合使得我可以使用kafka的非常低延迟的pipelines.

有关Kafka提供的保证，apis和功能的更多信息，请参阅其余的文档.




